{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize_de(text):\n",
    "    # Tokenizes German text from a string into a list of strings\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    # Tokenizes English text from a string into a list of strings\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tensorflow/envs/torch/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SRC = Field(tokenize = tokenize_de, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tensorflow/envs/torch/lib/python3.6/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'),fields = (SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tensorflow/envs/torch/lib/python3.6/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 96\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,input_dim,emb_dim,enc_hid_dim,dec_hid_dim,dropout):\n",
    "        super().__init__()\n",
    "        self.num_layers = 1\n",
    "        self.bidirectional = True\n",
    "        self.embedding = nn.Embedding(input_dim,emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim,enc_hid_dim,num_layers=self.num_layers,dropout=dropout,bidirectional=self.bidirectional)\n",
    "        self.fc = nn.Linear(enc_hid_dim*(2 if self.bidirectional else 1),dec_hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self,src):\n",
    "        '''\n",
    "        src= [src_len,batch_size]\n",
    "        '''\n",
    "        src = src.transpose(0,1) #[batch_size,src_len]\n",
    "        embedded = self.dropout(self.embedding(src)).transpose(0,1)  #[src_len,batch_size,emb_dim]\n",
    "        #enc_output [src_len,batch_size,num_directions * hidden_size]\n",
    "        #enc_hidden [num_layers * num_directions, batch, hidden_size]\n",
    "        enc_output,enc_hidden = self.rnn(embedded)  \n",
    "        if self.bidirectional:\n",
    "            hidden = torch.cat((enc_hidden[-1,:,:],enc_hidden[-2,:,:]),dim = 1)\n",
    "        else:\n",
    "            hidden = enc_hidden[-1,:,:]\n",
    "        #s = [batch,dec_hid_dim]\n",
    "        s = torch.tanh(self.fc(hidden))\n",
    "        \n",
    "        return enc_output,s\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,output_dim,emb_dim,enc_hid_dim,dec_hid_dim,dropout):\n",
    "        super().__init__()\n",
    "        self.num_layers = 1\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim,emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim,dec_hid_dim,num_layers=self.num_layers,dropout=dropout)\n",
    "        self.fc = nn.Linear(dec_hid_dim,output_dim)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "    def forward(self,dec_input,s):\n",
    "        '''\n",
    "        dec_input = [batch_size]\n",
    "        s = [num_layers ,batch_size, dec_hid_dim]\n",
    "        '''\n",
    "        dec_input = dec_input.unsqueeze(1) # dec_input = [batch_size, 1]\n",
    "        \n",
    "        # embedded = [1,batch_size,dec_emb_dim]\n",
    "        embedded = self.drop(self.embedding(dec_input)).transpose(0,1)\n",
    "        #dec_output [1,batch_size,dec_hid_dim]\n",
    "        #dec_hidden = [num_layers,batch_size,dec_hid_dim]\n",
    "        dec_output,dec_hidden = self.rnn(embedded,s)\n",
    "        \n",
    "        #dec_output = [batch_size,dec_hid_dim]\n",
    "        dec_output = dec_output.squeeze(0)\n",
    "        \n",
    "        #dec_output [batch_size,out_dim]\n",
    "        dec_output = self.fc(dec_output)\n",
    "        \n",
    "        return dec_output,dec_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "    def  __init__(self,encoder,decoder):\n",
    "        super(Seq2seq,self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    def forward(self,src, target,teacher_forcing_ratio=0.5):\n",
    "        # src = [src_len, batch_size]\n",
    "        # trg = [trg_len, batch_size]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = target.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #enc_out = [src_len,batch_size,num_directions * hidden_size]\n",
    "        #s = [batch_size,dec_hid_dim]\n",
    "        enc_out,s = self.encoder(src)\n",
    "        \n",
    "        s = s.repeat(self.decoder.num_layers,1,1)\n",
    "        #outputs [batch_size,trg_len,trg_vocab_size]\n",
    "        outputs = torch.zeros(trg_len,batch_size,trg_vocab_size).cuda()\n",
    "        input = target[0,:]\n",
    "        for i in range(trg_len):\n",
    "            dec_out,s = self.decoder(input,s)\n",
    "            outputs[i,:,:] = dec_out\n",
    "            \n",
    "            # get the highest predicted token from our predictions\n",
    "            top1 = dec_out.argmax(1) \n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            input = target[i,:] if teacher_force else top1\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = Encoder(len(SRC.vocab),10,128,128,0).cuda()\n",
    "decode = Decoder(len(TRG.vocab),10,128,128,0).cuda()\n",
    "model = Seq2seq(encode,decode).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss = 0\n",
    "for batch in train_iterator:\n",
    "    src = batch.src.cuda()\n",
    "    trg = batch.trg.cuda() # trg = [trg_len, batch_size]\n",
    "    pred = model(src,trg)\n",
    "    pred_dim = pred.shape[-1]\n",
    "    # trg = [(trg len - 1) * batch size]\n",
    "    # pred = [(trg len - 1) * batch size, pred_dim]\n",
    "    trg = trg[1:].view(-1)\n",
    "    pred = pred[1:].view(-1, pred_dim)\n",
    "        \n",
    "    loss = criterion(pred, trg)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    epoch_loss += loss.item()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1824, -0.0137,  0.9211],\n",
      "        [-0.8134,  0.6702, -0.4294],\n",
      "        [-0.2126, -0.8452, -1.4732],\n",
      "        [-1.1824, -0.0137,  0.9211],\n",
      "        [-0.8134,  0.6702, -0.4294],\n",
      "        [-0.2126, -0.8452, -1.4732]])\n"
     ]
    }
   ],
   "source": [
    "print(a.repeat(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
